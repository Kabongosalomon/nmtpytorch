#!/usr/bin/env python
import os
import sys
import argparse
import subprocess

# These imports should not call Logger() or the log file will not be
# recorded
from nmtpytorch.config import Config
from nmtpytorch.utils.device import DeviceManager
from nmtpytorch.utils.misc import get_temp_file


def prepare(bash_script):
    tmp_file = get_temp_file(close=True, executable=True)
    with open(tmp_file.name, 'w') as f:
        f.write(bash_script)
    subprocess.check_output(tmp_file.name, universal_newlines=True)


def setup_experiment(opts, suffix=None, short=False):
    """Return a representative string for the experiment."""

    import time
    import random
    import pathlib
    import hashlib

    # subfolder is conf filename without .conf suffix
    opts.train['subfolder'] = pathlib.Path(opts.filename).stem

    # add suffix to subfolder name to keep experiment names shorter
    if suffix:
        opts.train['subfolder'] += "-{}".format(suffix)

    # Create folders
    folder = pathlib.Path(opts.train['save_path']) / opts.train['subfolder']
    folder.mkdir(parents=True, exist_ok=True)

    # Set random experiment ID
    run_id = time.strftime('%Y%m%d%H%m%S') + str(random.random())
    run_id = hashlib.sha256(run_id.encode('ascii')).hexdigest()[:5]

    # Finalize
    model_type = opts.train['model_type'].lower()
    opts.train['exp_id'] = f'{model_type}-r{run_id}'


if __name__ == '__main__':
    parser = argparse.ArgumentParser(
        prog='nmtpy',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        description="nmtpy trains/translates/tests a given "
                    "configuration/checkpoint/snapshot",
        argument_default=argparse.SUPPRESS)

    subparsers = parser.add_subparsers(dest='cmd', title='sub-commands',
                                       description='Valid sub-commands')

    # train command
    parser_train = subparsers.add_parser('train', help='train help')
    parser_train.add_argument('-C', '--config', type=str, required=True,
                              help="Experiment configuration file")
    parser_train.add_argument('-s', '--suffix', type=str, default="",
                              help="Optional experiment suffix.")
    parser_train.add_argument('-d', '--device-id', type=str, default='1gpu',
                              help='cpu or [N]gpu cuda (Default: 1gpu)')
    parser_train.add_argument('overrides', nargs="*", default=[],
                              help="(section).key:value overrides for config")

    ###################
    # translate command
    ###################
    parser_trans = subparsers.add_parser('translate', help='translate help')
    parser_trans.add_argument('-u', '--suppress-unk', action='store_true',
                              help='Do not generate <unk> tokens.')
    parser_trans.add_argument('-n', '--disable-filters', action='store_true',
                              help='Disable eval_filters given in config')
    parser_trans.add_argument('-N', '--n-best', action='store_true',
                              help='Generate n-best list of beam candidates.')
    parser_trans.add_argument('-b', '--batch-size', type=int, default=16,
                              help='Batch size for beam-search')
    parser_trans.add_argument('-k', '--beam-size', type=int, default=6,
                              help='Beam size for beam-search')
    parser_trans.add_argument('-m', '--max-len', type=int, default=200,
                              help='Maximum sequence length to produce (Default: 200)')
    parser_trans.add_argument('-a', '--lp-alpha', type=float, default=0.,
                              help='Apply length-penalty (Default: 0.)')
    parser_trans.add_argument('-d', '--device-id', type=str, default='gpu',
                              help='cpu or gpu (Default: gpu)')
    parser_trans.add_argument('models', type=str, nargs='+',
                              help="Saved model/checkpoint file(s)")
    parser_trans.add_argument('-tid', '--task-id', type=str, default=None,
                              help='Task to perform, e.g. en_src:Text, pt_src:Text -> fr_tgt:Text')
    parser_trans.add_argument('-x', '--override', nargs="*", default=[],
                              help="(section).key:value overrides for config")
    parser_trans.add_argument('-r', '--stochastic', action='store_true',
                              help="Don't fix seed for sampling-based models.")
    parser_trans.add_argument('-f', '--beam-func', default='beam_search',
                              help="Use a custom beam search method defined in the model.")

    # You can translate a set of splits defined in the .conf file
    parser_trans.add_argument('-s', '--splits', type=str, required=True,
                              help='Comma separated splits from config file')
    # Or you can provide another input configuration with -S
    # With this, the previous -s is solely used for the naming of the output file
    # and you can only give 1 split with -s that corresponds to new input you
    # define with -S.
    parser_trans.add_argument('-S', '--source', type=str, default=None,
                              help='Comma-separated key:value pairs to provide new inputs.')
    parser_trans.add_argument('-o', '--output', type=str, required=True,
                              help='Output filename prefix')

    ##############
    # test command
    ##############
    parser_test = subparsers.add_parser('test', help='test help')
    parser_test.add_argument('-b', '--batch-size', type=int, default=64,
                             help='Batch size for beam-search')
    parser_test.add_argument('-d', '--device-id', type=str, default='gpu',
                             help='cpu or gpu (Default: gpu)')
    parser_test.add_argument('models', type=str, nargs='+',
                             help="Saved model/checkpoint file(s)")
    parser_test.add_argument('-tid', '--task-id', type=str, default=None,
                             help='Task to perform, e.g. en_src:Text, pt_src:Text -> fr_tgt:Text')
    parser_test.add_argument('-x', '--override', nargs="*", default=[],
                             help="(section).key:value overrides for config")
    parser_test.add_argument('-m', '--mode', choices=['eval', 'enc'],
                             default='eval',
                             help="Perform evaluation or dump encodings.")
    parser_test.add_argument('-s', '--splits', type=str,
                             help='Comma separated splits from config file')
    parser_test.add_argument('-S', '--source', type=str,
                             help='Comma-separated key:value pairs to provide new inputs.')
    parser_test.add_argument('-r', '--stochastic', action='store_true',
                             help="Don't fix seed for sampling-based models.")

    # Parse command-line arguments first
    args = parser.parse_args()
    if args.cmd is None:
        parser.print_help()
        sys.exit(1)

    # Reserve device(s)
    dev_mgr = DeviceManager(args.device_id)

    from nmtpytorch.logger import Logger

    # Mode selection
    if args.cmd == 'train':

        # Parse configuration file and merge with the rest
        opts = Config(args.config, args.overrides)

        # Setup experiment folders
        setup_experiment(opts, args.suffix)

    # setup logger
    log = Logger(opts.train)

    from nmtpytorch.utils.misc import fix_seed

    # translate entry point
    if args.cmd in ('translate', 'test'):
        # no logging to file in inference mode
        Logger.setup(None)
        if not args.stochastic:
            fix_seed(1234)
        cmd = args.__dict__.pop('cmd')
        if cmd == 'translate':
            from nmtpytorch.translator import Translator
            translator = Translator(**args.__dict__)
            translator()
        elif cmd == 'test':
            from nmtpytorch.tester import Tester
            tester = Tester(**args.__dict__)
            tester()
        sys.exit(0)

    ############################################################
    # Check if the configuration includes a preprocessing script
    ############################################################
    if opts.prepare_script:
        log.log_header('Preparation script found! Running it')
        prepare(opts.prepare_script)

    #################################
    # Training / Resuming entry point
    #################################
    import torch
    import platform
    import nmtpytorch
    from nmtpytorch import models
    from nmtpytorch.mainloop import MainLoop

    # If given, seed that; if not generate a random seed and print it
    from nmtpytorch.utils.misc import fix_seed
    if opts.train['seed'] > 0:
        seed = fix_seed(opts.train['seed'])
    else:
        opts.train['seed'] = fix_seed()

    log.log_header('Experiment configuration')
    log.log(opts)

    # Instantiate the model object
    model = getattr(models, opts.train['model_type'])(opts=opts)

    log.log_header('Software details')
    log.log("Python {} -- torch {} with CUDA {} (on machine '{}')".format(
        platform.python_version(), torch.__version__,
        torch.version.cuda, platform.node()))
    log.log(f"nmtpytorch {nmtpytorch.__version__}")
    log.log(dev_mgr)
    log.log(f"Seed for further reproducibility: {opts.train['seed']}")

    if 'SLURM_JOB_ID' in os.environ:
        log.log(f"SLURM Job ID: {os.environ['SLURM_JOB_ID']}")

    log.log_header('Creating mainloop')
    loop = MainLoop(model, opts, dev_mgr)
    loop()
    sys.exit(0)
